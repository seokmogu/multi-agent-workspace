# ì›¹ ìŠ¤í¬ë˜í•‘ Arsenal - ì „ë°©ìœ„ ë„êµ¬ ë¹„êµ ë° í´ë°± ì „ëµ

> ëª¨ë“  ìƒí™©ì— ëŒ€ë¹„í•œ ìŠ¤í¬ë˜í•‘ ë„êµ¬ ì¢…í•© ê°€ì´ë“œ

**ì² í•™**: "í•œ ê°€ì§€ ë„êµ¬ë¡œ ëª¨ë“  ê²ƒì„ í•  ìˆ˜ ì—†ë‹¤. ìƒí™©ì— ë”°ë¼ ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³ , ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ë„êµ¬ë¡œ í´ë°±í•œë‹¤."

---

## ğŸ“‹ ëª©ì°¨

1. [ë„êµ¬ ì „ì²´ ë¹„êµí‘œ](#ë„êµ¬-ì „ì²´-ë¹„êµí‘œ)
2. [ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜](#ì¹´í…Œê³ ë¦¬ë³„-ë¶„ë¥˜)
3. [í´ë°± ì²´ì¸ ì „ëµ](#í´ë°±-ì²´ì¸-ì „ëµ)
4. [ìƒí™©ë³„ ìµœì  ë„êµ¬](#ìƒí™©ë³„-ìµœì -ë„êµ¬)
5. [êµ¬í˜„ ì˜ˆì‹œ](#êµ¬í˜„-ì˜ˆì‹œ)

---

## ë„êµ¬ ì „ì²´ ë¹„êµí‘œ

### ë¬´ë£Œ/ì˜¤í”ˆì†ŒìŠ¤ ê³„ì¸µ

| ë„êµ¬ | íƒ€ì… | ê°€ê²© | JavaScript | Anti-Bot | LLM ì¶”ì¶œ | í¬ë¡¤ë§ | ì†ë„ | GitHub Stars |
|------|------|------|-----------|---------|----------|--------|------|--------------|
| **Jina AI** | API | ë¬´ë£Œ (100ë§Œ í† í°) | âš ï¸ ë¶€ë¶„ | âŒ | âŒ | âŒ | âš¡âš¡âš¡ | - |
| **Crawl4AI** | ì˜¤í”ˆì†ŒìŠ¤ | ë¬´ë£Œ | âœ… | âš ï¸ ê¸°ë³¸ | âœ… | âœ… | âš¡âš¡âš¡ | 10K+ |
| **ScrapeGraphAI** | ì˜¤í”ˆì†ŒìŠ¤ | ë¬´ë£Œ | âœ… | âš ï¸ ê¸°ë³¸ | âœ…âœ… | âœ… | âš¡âš¡ | 20K+ |
| **Scrapy** | í”„ë ˆì„ì›Œí¬ | ë¬´ë£Œ | âš ï¸ ì¶”ê°€ | âŒ | âŒ | âœ…âœ… | âš¡âš¡âš¡ | 52K+ |
| **BeautifulSoup** | ë¼ì´ë¸ŒëŸ¬ë¦¬ | ë¬´ë£Œ | âŒ | âŒ | âŒ | âŒ | âš¡âš¡âš¡ | - |
| **Playwright** | ë¸Œë¼ìš°ì € | ë¬´ë£Œ | âœ…âœ… | âš ï¸ ìˆ˜ë™ | âŒ | âš ï¸ | âš¡ | 65K+ |

### ìœ ë£Œ API ê³„ì¸µ

| ë„êµ¬ | ê°€ê²©/ì›” | JavaScript | Anti-Bot | LLM ì¶”ì¶œ | í¬ë¡¤ë§ | ì„±ê³µë¥  | Proxy |
|------|---------|-----------|---------|----------|--------|--------|-------|
| **Firecrawl** | $16-83 | âœ…âœ… | âš ï¸ ê¸°ë³¸ | âœ…âœ… | âœ…âœ… | ~90% | âš ï¸ |
| **ScraperAPI** | $49+ | âœ…âœ… | âœ…âœ… | âŒ | âš ï¸ | 99.99% | âœ…âœ… |
| **Apify** | $49+ | âœ…âœ… | âœ… | âš ï¸ | âœ…âœ… | ~95% | âœ… |
| **Bright Data** | $500+ | âœ…âœ… | âœ…âœ…âœ… | âœ… | âœ…âœ… | 99.9% | âœ…âœ…âœ… |
| **ZenRows** | $69+ | âœ…âœ… | âœ…âœ… | âŒ | âš ï¸ | ~98% | âœ…âœ… |
| **Oxylabs** | $99+ | âœ…âœ… | âœ…âœ… | âœ… | âœ… | ~98% | âœ…âœ… |

### íŠ¹ìˆ˜ ëª©ì  ë„êµ¬

| ë„êµ¬ | ì „ë¬¸ ë¶„ì•¼ | ê°€ê²© | íŠ¹ì§• |
|------|-----------|------|------|
| **Jina Embeddings** | ë©€í‹°ëª¨ë‹¬ ì„ë² ë”© | API ìš”ê¸ˆ | Text + Image ì„ë² ë”© |
| **Jina Reranker** | ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬ | API ìš”ê¸ˆ | ì •í™•ë„ í–¥ìƒ |
| **Whisper** | ì˜¤ë””ì˜¤ ì „ì‚¬ | ë¬´ë£Œ/API | YouTube, íŒŸìºìŠ¤íŠ¸ |
| **Unstructured** | ë¬¸ì„œ íŒŒì‹± | ë¬´ë£Œ/API | PDF, Word, Excel |

---

## ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜

### Tier 1: ë¬´ë£Œ ê³ ì„±ëŠ¥ (1ì°¨ ì‹œë„)

```
ğŸ¥‡ Jina AI Reader
   âœ… ì™„ì „ ë¬´ë£Œ (100ë§Œ í† í°)
   âœ… ì´ˆê³ ì† (2-3ì´ˆ)
   âœ… ì´ë¯¸ì§€ ìë™ ìº¡ì…”ë‹
   âœ… Search API ë‚´ì¥
   âŒ í¬ë¡¤ë§ ë¶ˆê°€
   âŒ JavaScript ì œí•œ
   Use Case: ë‰´ìŠ¤, ë¸”ë¡œê·¸, ë‹¨ìˆœ í˜ì´ì§€

ğŸ¥ˆ Crawl4AI
   âœ… ì™„ì „ ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)
   âœ… ì´ˆê³ ì†
   âœ… LLM-friendly ì¶œë ¥
   âœ… í¬ë¡¤ë§ ì§€ì›
   âš ï¸ Anti-bot ê¸°ë³¸ë§Œ
   Use Case: ëŒ€ëŸ‰ í¬ë¡¤ë§, ë¡œì»¬ ì‹¤í–‰

ğŸ¥‰ ScrapeGraphAI
   âœ… ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)
   âœ… í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì¶”ì¶œ
   âœ… ë©€í‹° LLM ì§€ì›
   âš ï¸ ì†ë„ ëŠë¦¼
   Use Case: ë³µì¡í•œ êµ¬ì¡°í™” ì¶”ì¶œ
```

### Tier 2: ì €ë¹„ìš© ìœ ë£Œ (2ì°¨ í´ë°±)

```
ğŸ¥‡ Firecrawl
   ğŸ’° $16-83/ì›”
   âœ… LLM Extract ê°•ë ¥
   âœ… ì „ì²´ ì‚¬ì´íŠ¸ í¬ë¡¤ë§
   âœ… Screenshot
   âš ï¸ Anti-bot ë³´í†µ
   Use Case: IR í˜ì´ì§€, êµ¬ì¡°í™” ì¶”ì¶œ

ğŸ¥ˆ Apify
   ğŸ’° $49+/ì›”
   âœ… 1,600+ ì‚¬ì „ êµ¬ì¶• ìŠ¤í¬ë˜í¼
   âœ… í”Œë«í¼ ìƒíƒœê³„
   âœ… ìë™í™” ì›Œí¬í”Œë¡œìš°
   âš ï¸ ë¹„ìš© ì¦ê°€ ë¹ ë¦„
   Use Case: íŠ¹ì • ì‚¬ì´íŠ¸ (LinkedIn, Amazon)
```

### Tier 3: Anti-Bot ì „ë¬¸ (3ì°¨ í´ë°±)

```
ğŸ¥‡ ScraperAPI
   ğŸ’° $49+/ì›” (ì„±ê³µ ìš”ì²­ë§Œ ê³¼ê¸ˆ)
   âœ… 99.99% ì„±ê³µë¥ 
   âœ… Cloudflare, DataDome ìš°íšŒ
   âœ… CAPTCHA ìë™ í•´ê²°
   âœ… Residential IP ìˆ˜ë°±ë§Œ ê°œ
   Use Case: ë³´í˜¸ëœ ì‚¬ì´íŠ¸

ğŸ¥ˆ Bright Data
   ğŸ’° $500+/ì›” (ì—”í„°í”„ë¼ì´ì¦ˆ)
   âœ… ìµœê°• Anti-bot
   âœ… 7,200ë§Œ+ IP
   âœ… ì „ìš© ìŠ¤í¬ë˜í•‘ ë¸Œë¼ìš°ì €
   Use Case: ëŒ€ê·œëª¨ ì—”í„°í”„ë¼ì´ì¦ˆ
```

### Tier 4: DIY/ì»¤ìŠ¤í…€ (ìµœí›„ ìˆ˜ë‹¨)

```
ğŸ¥‡ Playwright + Proxy
   âœ… ì™„ì „í•œ ì œì–´
   âœ… ë¸Œë¼ìš°ì € ìë™í™”
   âš ï¸ ëŠë¦¼
   âš ï¸ ê´€ë¦¬ ë¶€ë‹´
   Use Case: íŠ¹ìˆ˜ ì¼€ì´ìŠ¤

ğŸ¥ˆ Scrapy + Rotating Proxy
   âœ… ëŒ€ëŸ‰ í¬ë¡¤ë§
   âœ… ì»¤ìŠ¤í„°ë§ˆì´ì§•
   âš ï¸ Anti-bot ìˆ˜ë™ ëŒ€ì‘
   Use Case: ì •ì  ì‚¬ì´íŠ¸ ëŒ€ëŸ‰ ìˆ˜ì§‘
```

---

## í´ë°± ì²´ì¸ ì „ëµ

### ì§€ëŠ¥í˜• í´ë°± ì‹œìŠ¤í…œ

```python
class SmartScraperWithFallback:
    """
    ìë™ í´ë°± ì›¹ ìŠ¤í¬ë˜í¼

    ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ë„êµ¬ë¡œ ìë™ ì „í™˜
    """

    def __init__(self):
        # Tier 1: ë¬´ë£Œ
        self.jina = JinaReader()
        self.crawl4ai = Crawl4AIClient()

        # Tier 2: ì €ë¹„ìš©
        self.firecrawl = FirecrawlApp(api_key="...")
        self.apify = ApifyClient(token="...")

        # Tier 3: Anti-bot
        self.scraperapi = ScraperAPIClient(api_key="...")

        # Tier 4: DIY
        self.playwright = PlaywrightBrowser()

        # í†µê³„
        self.stats = {
            "jina": {"success": 0, "failure": 0},
            "crawl4ai": {"success": 0, "failure": 0},
            "firecrawl": {"success": 0, "failure": 0},
            "scraperapi": {"success": 0, "failure": 0},
            "playwright": {"success": 0, "failure": 0}
        }

    async def scrape(self, url: str, options: dict = None) -> dict:
        """
        í´ë°± ì²´ì¸ì„ í†µí•œ ìŠ¤í¬ë˜í•‘

        Args:
            url: ëŒ€ìƒ URL
            options: {
                'task_type': 'news' | 'website' | 'protected',
                'require_javascript': bool,
                'require_structure': bool,
                'max_cost': float
            }

        Returns:
            {
                'success': bool,
                'content': str,
                'tool_used': str,
                'cost': float,
                'attempts': list
            }
        """

        options = options or {}
        task_type = options.get('task_type', 'general')
        attempts = []

        # í´ë°± ì²´ì¸ ì •ì˜
        chain = self._build_fallback_chain(url, options)

        for tool_name, scraper_func in chain:
            try:
                print(f"ğŸ”„ Trying {tool_name}...")

                result = await scraper_func(url, options)

                # ì„±ê³µ í™•ì¸
                if self._validate_result(result):
                    self.stats[tool_name]["success"] += 1
                    attempts.append({
                        "tool": tool_name,
                        "status": "success"
                    })

                    return {
                        "success": True,
                        "content": result["content"],
                        "tool_used": tool_name,
                        "cost": result.get("cost", 0),
                        "attempts": attempts
                    }

            except Exception as e:
                self.stats[tool_name]["failure"] += 1
                attempts.append({
                    "tool": tool_name,
                    "status": "failed",
                    "error": str(e)
                })
                print(f"âŒ {tool_name} failed: {e}")
                continue

        # ëª¨ë‘ ì‹¤íŒ¨
        return {
            "success": False,
            "content": None,
            "tool_used": None,
            "cost": 0,
            "attempts": attempts
        }

    def _build_fallback_chain(self, url: str, options: dict) -> list:
        """
        URLê³¼ ì˜µì…˜ì— ë”°ë¼ ìµœì ì˜ í´ë°± ì²´ì¸ êµ¬ì„±

        Returns:
            [(tool_name, scraper_function), ...]
        """

        task_type = options.get('task_type')
        require_js = options.get('require_javascript', False)
        require_anti_bot = self._detect_anti_bot(url)
        max_cost = options.get('max_cost', 100)  # ìµœëŒ€ í—ˆìš© ë¹„ìš©

        chain = []

        # ë‰´ìŠ¤/ê²€ìƒ‰ â†’ Jina AI ìš°ì„ 
        if task_type == 'news' or task_type == 'search':
            chain.append(('jina', self._scrape_with_jina))

        # ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸ â†’ ë¬´ë£Œ ë„êµ¬ ìš°ì„ 
        if not require_anti_bot:
            chain.append(('jina', self._scrape_with_jina))
            if require_js:
                chain.append(('crawl4ai', self._scrape_with_crawl4ai))

        # êµ¬ì¡°í™” í•„ìš” â†’ Firecrawl
        if options.get('require_structure'):
            if max_cost >= 0.016:  # Firecrawl 1 credit
                chain.append(('firecrawl', self._scrape_with_firecrawl))

        # Anti-bot ê°ì§€ â†’ ì „ë¬¸ ë„êµ¬
        if require_anti_bot:
            if max_cost >= 1:  # ScraperAPI ~$1/1000 requests
                chain.append(('scraperapi', self._scrape_with_scraperapi))

        # ìµœí›„ ìˆ˜ë‹¨ â†’ DIY
        chain.append(('playwright', self._scrape_with_playwright))

        return chain

    def _detect_anti_bot(self, url: str) -> bool:
        """
        URLì—ì„œ Anti-bot ì‹œìŠ¤í…œ ê°ì§€

        Returns:
            True if anti-bot detected
        """

        # ì•Œë ¤ì§„ ë³´í˜¸ ì‹œìŠ¤í…œì´ ìˆëŠ” ë„ë©”ì¸
        protected_domains = [
            'cloudflare',
            'datadome',
            'perimeterx',
            'akamai'
        ]

        # ê°„ë‹¨í•œ GET ìš”ì²­ìœ¼ë¡œ í™•ì¸
        try:
            response = requests.get(url, timeout=5)

            # Cloudflare ê°ì§€
            if 'cf-ray' in response.headers:
                return True

            # DataDome ê°ì§€
            if 'datadome' in response.text.lower():
                return True

            # CAPTCHA ê°ì§€
            if 'captcha' in response.text.lower():
                return True

        except:
            pass

        return False

    def _validate_result(self, result: dict) -> bool:
        """
        ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ê²€ì¦

        Returns:
            True if result is valid
        """

        if not result or not result.get("content"):
            return False

        content = result["content"]

        # ìµœì†Œ ê¸¸ì´ í™•ì¸
        if len(content) < 100:
            return False

        # ì—ëŸ¬ í˜ì´ì§€ ê°ì§€
        error_keywords = [
            "access denied",
            "403 forbidden",
            "404 not found",
            "rate limit",
            "captcha"
        ]

        content_lower = content.lower()
        for keyword in error_keywords:
            if keyword in content_lower:
                return False

        return True

    # ê° ë„êµ¬ë³„ ë˜í¼ í•¨ìˆ˜
    async def _scrape_with_jina(self, url: str, options: dict) -> dict:
        """Jina AIë¡œ ìŠ¤í¬ë˜í•‘"""
        result = self.jina.read(url)
        return {
            "content": result["markdown"],
            "cost": 0
        }

    async def _scrape_with_crawl4ai(self, url: str, options: dict) -> dict:
        """Crawl4AIë¡œ ìŠ¤í¬ë˜í•‘"""
        result = await self.crawl4ai.arun(url)
        return {
            "content": result.markdown,
            "cost": 0
        }

    async def _scrape_with_firecrawl(self, url: str, options: dict) -> dict:
        """Firecrawlë¡œ ìŠ¤í¬ë˜í•‘"""

        if options.get('require_structure'):
            result = await self.firecrawl.scrape_url(
                url,
                params={
                    'formats': ['extract'],
                    'extract': {'schema': options.get('schema')}
                }
            )
        else:
            result = await self.firecrawl.scrape_url(
                url,
                params={'formats': ['markdown']}
            )

        return {
            "content": result["markdown"],
            "cost": 0.016  # 1 credit
        }

    async def _scrape_with_scraperapi(self, url: str, options: dict) -> dict:
        """ScraperAPIë¡œ ìŠ¤í¬ë˜í•‘"""

        api_url = f"http://api.scraperapi.com/?api_key={self.scraperapi.api_key}&url={url}"

        if options.get('require_javascript'):
            api_url += "&render=true"

        response = requests.get(api_url)

        return {
            "content": response.text,
            "cost": 0.001  # ~$1/1000 requests
        }

    async def _scrape_with_playwright(self, url: str, options: dict) -> dict:
        """Playwrightë¡œ ìŠ¤í¬ë˜í•‘ (ìµœí›„ ìˆ˜ë‹¨)"""

        async with self.playwright as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()

            await page.goto(url, wait_until="networkidle")
            content = await page.content()

            await browser.close()

        return {
            "content": content,
            "cost": 0  # ì„œë²„ ë¹„ìš©ë§Œ
        }

    def print_stats(self):
        """í†µê³„ ì¶œë ¥"""
        print("\nğŸ“Š Scraping Statistics:")
        for tool, stats in self.stats.items():
            total = stats["success"] + stats["failure"]
            if total > 0:
                success_rate = stats["success"] / total * 100
                print(f"  {tool}: {stats['success']}/{total} ({success_rate:.1f}% success)")
```

---

## ìƒí™©ë³„ ìµœì  ë„êµ¬

### ì‹œë‚˜ë¦¬ì˜¤ 1: í•œêµ­ ë‰´ìŠ¤ ìˆ˜ì§‘

```
ëª©í‘œ: ë„¤ì´ë²„ ë‰´ìŠ¤ 1,000ê°œ ê¸°ì‚¬ ìˆ˜ì§‘

í´ë°± ì²´ì¸:
1. Jina AI Search (ë¬´ë£Œ) â† 1ìˆœìœ„
2. Naver Search API (ë¬´ë£Œ) â† 2ìˆœìœ„
3. Crawl4AI (ë¬´ë£Œ) â† 3ìˆœìœ„

ì˜ˆìƒ ë¹„ìš©: $0
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ ë¶„ì„

```
ëª©í‘œ: íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ About, IR, ì±„ìš© í˜ì´ì§€

í´ë°± ì²´ì¸:
1. Jina AI Reader (ë¬´ë£Œ) â† ë¹ ë¥¸ ê°œìš”
2. Firecrawl (ìœ ë£Œ) â† ìƒì„¸ ë¶„ì„ (10 í˜ì´ì§€)
3. Playwright (ë¬´ë£Œ) â† JavaScript í•„ìš”ì‹œ

ì˜ˆìƒ ë¹„ìš©: ~$0.16 (Firecrawl 10 credits)
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: LinkedIn í”„ë¡œí•„ ìˆ˜ì§‘

```
ëª©í‘œ: ì„ì› 100ëª… LinkedIn í”„ë¡œí•„

Anti-bot: âœ… (LinkedInì€ ê°•ë ¥)

í´ë°± ì²´ì¸:
1. Apify LinkedIn Scraper (ìœ ë£Œ) â† ì „ë¬¸
2. ScraperAPI (ìœ ë£Œ) â† Anti-bot ìš°íšŒ
3. Bright Data (ìœ ë£Œ) â† ìµœí›„ ìˆ˜ë‹¨

ì˜ˆìƒ ë¹„ìš©: $5-10 (Apify actor)
```

### ì‹œë‚˜ë¦¬ì˜¤ 4: DART ì¬ë¬´ì œí‘œ (PDF)

```
ëª©í‘œ: ì‚¬ì—…ë³´ê³ ì„œ PDF íŒŒì‹±

Anti-bot: âŒ

í´ë°± ì²´ì¸:
1. DART API (ë¬´ë£Œ) â† XML/JSONìœ¼ë¡œ ë°”ë¡œ
2. Unstructured (ë¬´ë£Œ) â† PDF íŒŒì‹±
3. PyPDF2 + GPT-4V (ìœ ë£Œ) â† OCR

ì˜ˆìƒ ë¹„ìš©: ~$0.05 (GPT-4V)
```

### ì‹œë‚˜ë¦¬ì˜¤ 5: YouTube IR ì˜ìƒ

```
ëª©í‘œ: IR í”„ë ˆì  í…Œì´ì…˜ ì˜ìƒ ë¶„ì„

í´ë°± ì²´ì¸:
1. YouTube Transcript API (ë¬´ë£Œ) â† ìë§‰ ìˆìœ¼ë©´
2. Whisper (ë¬´ë£Œ/API) â† ìë§‰ ì—†ìœ¼ë©´
3. GPT-4V (ìœ ë£Œ) â† í™”ë©´ ë¶„ì„

ì˜ˆìƒ ë¹„ìš©: $0-0.10
```

---

## ë„êµ¬ë³„ ìƒì„¸ ìŠ¤í™

### 1. Jina AI

**ê°•ì **:
- ì™„ì „ ë¬´ë£Œ (100ë§Œ í† í°)
- ì´ˆê³ ì† (2-3ì´ˆ)
- ì´ë¯¸ì§€ ìë™ ìº¡ì…”ë‹
- Search API ë‚´ì¥

**ì•½ì **:
- í¬ë¡¤ë§ ë¶ˆê°€
- JavaScript ë Œë”ë§ ì œí•œ
- Anti-bot ì—†ìŒ

**ìµœì  ì‚¬ìš©**:
```python
# ë‰´ìŠ¤, ë¸”ë¡œê·¸, ë‹¨ìˆœ ì›¹í˜ì´ì§€
jina.read("https://news.article.com")
jina.search("ì‚¼ì„±ì „ì M&A")
```

### 2. Crawl4AI

**ê°•ì **:
- ì™„ì „ ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)
- ì´ˆê³ ì† (ë©€í‹°ìŠ¤ë ˆë”©)
- LLM ì¹œí™”ì  ì¶œë ¥
- ë¡œì»¬ LLM ì§€ì›

**ì•½ì **:
- Anti-bot ê¸°ë³¸ë§Œ
- ì…€í”„ í˜¸ìŠ¤íŒ… í•„ìš”

**ìµœì  ì‚¬ìš©**:
```python
# ëŒ€ëŸ‰ í¬ë¡¤ë§, ë¹ ë¥¸ ì†ë„
from crawl4ai import AsyncWebCrawler

async with AsyncWebCrawler() as crawler:
    result = await crawler.arun(
        url="https://company.com",
        word_count_threshold=10
    )
```

### 3. ScrapeGraphAI

**ê°•ì **:
- í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì¶”ì¶œ
- ë©€í‹° LLM (GPT-4, Claude, Gemini)
- ìë™ êµ¬ì¡° ì¸ì‹

**ì•½ì **:
- ì†ë„ ëŠë¦¼
- LLM ë¹„ìš© ì¦ê°€

**ìµœì  ì‚¬ìš©**:
```python
# ë³µì¡í•œ êµ¬ì¡°í™” ì¶”ì¶œ
from scrapegraphai.graphs import SmartScraperGraph

graph = SmartScraperGraph(
    prompt="Extract product names, prices, ratings",
    source="https://shop.com",
    config={"llm": {"model": "gpt-4"}}
)

result = graph.run()
```

### 4. Firecrawl

**ê°•ì **:
- LLM Extract ê°•ë ¥
- ì „ì²´ ì‚¬ì´íŠ¸ í¬ë¡¤ë§
- Screenshot ì§€ì›

**ì•½ì **:
- ìœ ë£Œ ($16-83/ì›”)
- Anti-bot ë³´í†µ

**ìµœì  ì‚¬ìš©**:
```python
# IR í˜ì´ì§€, êµ¬ì¡°í™” ì¶”ì¶œ
firecrawl.scrape_url(
    "https://company.com/ir",
    params={
        'formats': ['extract'],
        'extract': {'schema': FINANCIAL_SCHEMA}
    }
)
```

### 5. ScraperAPI

**ê°•ì **:
- 99.99% ì„±ê³µë¥ 
- Cloudflare, DataDome ìš°íšŒ
- ì„±ê³µ ìš”ì²­ë§Œ ê³¼ê¸ˆ

**ì•½ì **:
- ë¹„ìš© ì¦ê°€ ê°€ëŠ¥
- LLM ì¶”ì¶œ ì—†ìŒ

**ìµœì  ì‚¬ìš©**:
```python
# ë³´í˜¸ëœ ì‚¬ì´íŠ¸
import requests

url = f"http://api.scraperapi.com/?api_key={API_KEY}&url=https://protected-site.com&render=true"
response = requests.get(url)
```

### 6. Apify

**ê°•ì **:
- 1,600+ ì‚¬ì „ êµ¬ì¶• ìŠ¤í¬ë˜í¼
- LinkedIn, Amazon, Google Maps ë“±
- ì›Œí¬í”Œë¡œìš° ìë™í™”

**ì•½ì **:
- ë¹„ìš© ì¦ê°€ ë¹ ë¦„
- Lock-in ìœ„í—˜

**ìµœì  ì‚¬ìš©**:
```python
# LinkedIn, íŠ¹ì • í”Œë«í¼
from apify_client import ApifyClient

client = ApifyClient("YOUR_TOKEN")

run = client.actor("apify/linkedin-profile-scraper").call(
    run_input={"profiles": ["https://linkedin.com/in/..."]}
)

for item in client.dataset(run["defaultDatasetId"]).iterate_items():
    print(item)
```

---

## ë¹„ìš© ì‹œë®¬ë ˆì´ì…˜

### ì‹œë‚˜ë¦¬ì˜¤: ì›” 100ê°œ ì¤‘ì†Œê¸°ì—… ë¦¬ì„œì¹˜

| íƒœìŠ¤í¬ | ë„êµ¬ | íšŸìˆ˜ | ë‹¨ê°€ | ë¹„ìš© |
|--------|------|------|------|------|
| ë‰´ìŠ¤ ê²€ìƒ‰ | Jina AI | 200 | $0 | **$0** |
| ì›¹ì‚¬ì´íŠ¸ ìŠ¤ìº” | Jina AI | 100 | $0 | **$0** |
| ì¬ë¬´ ë°ì´í„° | DART API | 100 | $0 | **$0** |
| IR ìƒì„¸ | Firecrawl | 50 | $0.016 | **$0.80** |
| LinkedIn | Apify | 20 | $0.25 | **$5** |
| ë³´í˜¸ ì‚¬ì´íŠ¸ | ScraperAPI | 10 | $0.001 | **$0.01** |
| LLM ë¶„ì„ | Claude | 100 | $0.50 | **$50** |
| **Total** | | | | **$55.81** |

**ê¸°ì¡´ (Firecrawlë§Œ)**: $83/ì›”
**ì ˆê°**: $27.19 (33% ì ˆê°)

---

## ìµœì¢… ê¶Œì¥ Arsenal

### í•µì‹¬ 3ì¢… ì„¸íŠ¸ (í•„ìˆ˜)

```
1. Jina AI (ë¬´ë£Œ)
   - ëª¨ë“  ì¼ë°˜ ìŠ¤í¬ë˜í•‘
   - ë‰´ìŠ¤, ê²€ìƒ‰, ì›¹ì‚¬ì´íŠ¸

2. DART/EDINET API (ë¬´ë£Œ)
   - í•œêµ­/ì¼ë³¸ ê³µì‹ ë°ì´í„°

3. Firecrawl ($16/ì›”)
   - IR ìƒì„¸ ë¶„ì„
   - êµ¬ì¡°í™” ì¶”ì¶œ
```

**ì›” ë¹„ìš©**: $16
**ì»¤ë²„ë¦¬ì§€**: 90%

### í™•ì¥ 5ì¢… ì„¸íŠ¸ (ê¶Œì¥)

```
+ 4. Crawl4AI (ë¬´ë£Œ)
     - ëŒ€ëŸ‰ í¬ë¡¤ë§
     - ë¡œì»¬ ì‹¤í–‰

+ 5. ScraperAPI ($49/ì›”)
     - Anti-bot ì‚¬ì´íŠ¸
     - ë³´í˜¸ëœ í˜ì´ì§€
```

**ì›” ë¹„ìš©**: $65
**ì»¤ë²„ë¦¬ì§€**: 98%

### ì—”í„°í”„ë¼ì´ì¦ˆ ì„¸íŠ¸ (ìµœëŒ€)

```
+ 6. Apify ($49/ì›”)
     - LinkedIn, Amazon
     - íŠ¹ìˆ˜ í”Œë«í¼

+ 7. Bright Data ($500+/ì›”)
     - ìµœê°• Anti-bot
     - ëŒ€ê·œëª¨ ìš´ì˜
```

**ì›” ë¹„ìš©**: $614
**ì»¤ë²„ë¦¬ì§€**: 99.9%

---

## ë‹¤ìŒ ë‹¨ê³„

### 1. ë¬´ë£Œ ë„êµ¬ í…ŒìŠ¤íŠ¸ (ì˜¤ëŠ˜)

```bash
# Jina AI
curl https://r.jina.ai/https://www.samsung.com

# Crawl4AI
pip install crawl4ai
crawl4ai-setup
```

### 2. í´ë°± ì‹œìŠ¤í…œ êµ¬í˜„ (1ì£¼)

```python
# smart_scraper.py êµ¬í˜„
scraper = SmartScraperWithFallback()
result = await scraper.scrape("https://company.com")
```

### 3. í”„ë¡œë•ì…˜ ë°°í¬ (1ê°œì›”)

```python
# ëª¨ë“  ë„êµ¬ í†µí•©
# í†µê³„ ìˆ˜ì§‘
# ë¹„ìš© ìµœì í™”
```

**ì§€ê¸ˆ ë°”ë¡œ ë¬´ë£Œ ë„êµ¬ë¶€í„° í…ŒìŠ¤íŠ¸í•´ë³¼ê¹Œìš”?**
