# A2A ê¸°ë°˜ ë¶„ì‚° ë©€í‹° ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜

> Google Agent2Agent (A2A) í”„ë¡œí† ì½œ ê¸°ë°˜ í”„ë¡œë•ì…˜ ë ˆë²¨ ë¶„ì‚° ì‹œìŠ¤í…œ ì„¤ê³„

**ë²„ì „**: 3.0.0-design
**ì‘ì„±ì¼**: 2025-10-22
**ìƒíƒœ**: Architecture Design (êµ¬í˜„ ì˜ˆì •)

---

## ğŸ“‹ ëª©ì°¨

1. [Executive Summary](#executive-summary)
2. [í”„ë¡œë•ì…˜ ìš”êµ¬ì‚¬í•­](#í”„ë¡œë•ì…˜-ìš”êµ¬ì‚¬í•­)
3. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
4. [ì—ì´ì „íŠ¸ ì„¤ê³„](#ì—ì´ì „íŠ¸-ì„¤ê³„)
5. [í†µì‹  í”„ë¡œí† ì½œ](#í†µì‹ -í”„ë¡œí† ì½œ)
6. [í™•ì¥ì„± ì „ëµ](#í™•ì¥ì„±-ì „ëµ)
7. [ì„±ëŠ¥ ë° ë¹„ìš©](#ì„±ëŠ¥-ë°-ë¹„ìš©)
8. [ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš](#ë§ˆì´ê·¸ë ˆì´ì…˜-ê³„íš)

---

## Executive Summary

### ë°°ê²½

**í˜„ì¬ ì‹œìŠ¤í…œ** (LangGraph ëª¨ë†€ë¦¬ì‹):
- ìˆœì°¨ ì²˜ë¦¬: 1,000ê°œ íšŒì‚¬ â†’ 12-25ì‹œê°„
- ì œí•œëœ í™•ì¥ì„±
- ë‹¨ì¼ ì¥ì• ì 

**í”„ë¡œë•ì…˜ ìš”êµ¬ì‚¬í•­**:
- âœ… ëŒ€ê·œëª¨ ë°°ì¹˜ ì²˜ë¦¬ (1,000+ íšŒì‚¬)
- âœ… ë³‘ë ¬ ì‹¤í–‰
- âœ… ë…ë¦½ í™•ì¥
- âœ… ì¥ì•  ë³µêµ¬
- âœ… 24/7 ìš´ì˜

### ì†”ë£¨ì…˜: A2A ê¸°ë°˜ ë¶„ì‚° ì‹œìŠ¤í…œ

**ì„±ëŠ¥ í–¥ìƒ**:
- ì²˜ë¦¬ ì‹œê°„: 12ì‹œê°„ â†’ **90ì´ˆ** (480ë°° ë¹ ë¦„)
- ì²˜ë¦¬ëŸ‰: 40/hour â†’ **400/hour** (10ë°°)
- íšŒì‚¬ë‹¹ ë¹„ìš©: $0.007 â†’ **$0.004** (40% ì ˆê°)

**ì•„í‚¤í…ì²˜ ì „í™˜**:
```
ëª¨ë†€ë¦¬ì‹ (v2.0)              ë¶„ì‚° ì‹œìŠ¤í…œ (v3.0)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤  â”‚            â”‚  API Gateway     â”‚
â”‚   Research    â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚      â†“        â”‚                     â†“
â”‚   Extraction  â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      â†“        â”‚            â”‚  Coordinator     â”‚
â”‚   Reflection  â”‚            â””â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â†“   â†“   â†“   â†“
                           R   E   R   S
                           e   x   e   t
                           s   t   f   o
                           e   r   l   r
                           a   a   e   a
                           r   c   c   g
                           c   t   t   e
                           h   i   i
                               o   o
                               n   n

                           (ê° 10, 5, 2, 1ê°œ ì¸ìŠ¤í„´ìŠ¤)
```

---

## í”„ë¡œë•ì…˜ ìš”êµ¬ì‚¬í•­

### 1. ì²˜ë¦¬ëŸ‰ ìš”êµ¬ì‚¬í•­

| ì‹œë‚˜ë¦¬ì˜¤ | ìš”êµ¬ì‚¬í•­ | í˜„ì¬ (v2.0) | ëª©í‘œ (v3.0) |
|---------|---------|------------|------------|
| **ë°°ì¹˜ ì²˜ë¦¬** | 1,000 companies | 12-25ì‹œê°„ | **90ì´ˆ** |
| **ì‹¤ì‹œê°„ ì²˜ë¦¬** | 50 req/min | ë¶ˆê°€ëŠ¥ (ìˆœì°¨) | **ê°€ëŠ¥** |
| **ë™ì‹œì„±** | 100+ concurrent | 1ê°œ | **100+** |
| **ì¼ì¼ ì²˜ë¦¬ëŸ‰** | 10,000 companies/day | 1,920 (80/h Ã— 24) | **9,600 (400/h Ã— 24)** |

### 2. ê°€ìš©ì„± ìš”êµ¬ì‚¬í•­

| í•­ëª© | ìš”êµ¬ì‚¬í•­ | êµ¬í˜„ ë°©ë²• |
|------|---------|----------|
| **Uptime** | 99.9% | ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤, ìë™ ë³µêµ¬ |
| **ì¥ì•  ë³µêµ¬** | < 1ë¶„ | Health check, Auto-restart |
| **ë¶€ë¶„ ì¥ì•  í—ˆìš©** | 997/1000 ì„±ê³µ | Agent ì¬ì‹œë„, Fallback |
| **ë°ì´í„° ë¬´ê²°ì„±** | 100% | Transaction, Idempotency |

### 3. í™•ì¥ì„± ìš”êµ¬ì‚¬í•­

| ë¦¬ì†ŒìŠ¤ | ë³‘ëª© | í™•ì¥ ì „ëµ |
|--------|------|----------|
| **Research** | Web search API | 10ê°œ ì¸ìŠ¤í„´ìŠ¤ (horizontal) |
| **Extraction** | LLM parsing | 5ê°œ ì¸ìŠ¤í„´ìŠ¤ (horizontal) |
| **Reflection** | ê°€ë²¼ì›€ | 2ê°œ ì¸ìŠ¤í„´ìŠ¤ |
| **Database** | I/O | Read replica, Connection pooling |

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Client Applications                     â”‚
â”‚                  (Web UI, CLI, API Client)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ HTTPS
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      API Gateway (Kong)                      â”‚
â”‚  - Authentication (JWT)                                      â”‚
â”‚  - Rate limiting (100 req/min)                              â”‚
â”‚  - Request validation                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ Internal HTTP
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Coordinator Agent (FastAPI)                 â”‚
â”‚  - Workflow orchestration                                    â”‚
â”‚  - Load balancing                                            â”‚
â”‚  - Error recovery                                            â”‚
â”‚  - Progress tracking                                         â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚             â”‚             â”‚             â”‚
   â”‚ A2A         â”‚ A2A         â”‚ A2A         â”‚ A2A
   â†“             â†“             â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Research â”‚  â”‚Extractionâ”‚  â”‚Reflectionâ”‚  â”‚ Storage  â”‚
â”‚Agents   â”‚  â”‚ Agents   â”‚  â”‚ Agents   â”‚  â”‚  Agent   â”‚
â”‚         â”‚  â”‚          â”‚  â”‚          â”‚  â”‚          â”‚
â”‚ 10ê°œ    â”‚  â”‚  5ê°œ     â”‚  â”‚  2ê°œ     â”‚  â”‚  1ê°œ     â”‚
â”‚instancesâ”‚  â”‚instances â”‚  â”‚instances â”‚  â”‚instance  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚             â”‚             â”‚
     â†“            â†“             â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Shared Infrastructure                      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ PostgreSQL   â”‚  â”‚  Redis   â”‚  â”‚   S3   â”‚  â”‚CloudWatchâ”‚ â”‚
â”‚  â”‚ (Primary +   â”‚  â”‚ (Cache + â”‚  â”‚ (Raw   â”‚  â”‚ (Logging â”‚ â”‚
â”‚  â”‚  Replica)    â”‚  â”‚  Queue)  â”‚  â”‚  Data) â”‚  â”‚ Metrics) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë„¤íŠ¸ì›Œí¬ ë ˆì´ì–´

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Internet                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Load Balancer (ALB)                       â”‚
â”‚                HTTPS (443)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Public Subnet (10.0.1.0/24)                 â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚  API Gateway     â”‚  (10.0.1.10)                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Private Subnet 1 (10.0.10.0/24)                â”‚
â”‚                 Application Tier                         â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚  Coordinator     â”‚  (10.0.10.10)                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚  Research-1~10   â”‚  (10.0.10.20-29)                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚  Extraction-1~5  â”‚  (10.0.10.30-34)                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚  Reflection-1~2  â”‚  (10.0.10.40-41)                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Private Subnet 2 (10.0.20.0/24)                â”‚
â”‚                   Data Tier                              â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  PostgreSQL      â”‚  â”‚  Redis           â”‚            â”‚
â”‚  â”‚  Primary         â”‚  â”‚  Primary         â”‚            â”‚
â”‚  â”‚  (10.0.20.10)    â”‚  â”‚  (10.0.20.20)    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  PostgreSQL      â”‚  â”‚  Redis           â”‚            â”‚
â”‚  â”‚  Replica         â”‚  â”‚  Replica         â”‚            â”‚
â”‚  â”‚  (10.0.20.11)    â”‚  â”‚  (10.0.20.21)    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ì—ì´ì „íŠ¸ ì„¤ê³„

### 1. Research Agent

**ëª©ì **: ì›¹ ê²€ìƒ‰ ë° ë¦¬ì„œì¹˜ ë…¸íŠ¸ ì‘ì„±

**Agent Card**:
```json
{
  "name": "ResearchAgent",
  "description": "Multi-source web research with Tavily/Google ADK",
  "url": "http://research-{instance-id}:5001",
  "version": "3.0.0",
  "capabilities": {
    "streaming": true,
    "pushNotifications": false,
    "parallelQueries": 10,
    "supportedProviders": ["tavily", "google_adk", "hybrid"]
  },
  "skills": [
    {
      "name": "research_company",
      "description": "Research company and generate structured notes",
      "input_schema": {
        "type": "object",
        "properties": {
          "company_name": {
            "type": "string",
            "description": "Target company name"
          },
          "extraction_schema": {
            "type": "object",
            "description": "JSON schema for data extraction"
          },
          "search_provider": {
            "type": "string",
            "enum": ["tavily", "google_adk", "hybrid"],
            "default": "hybrid"
          },
          "max_queries": {
            "type": "integer",
            "minimum": 1,
            "maximum": 10,
            "default": 3
          },
          "follow_up_queries": {
            "type": "array",
            "items": {"type": "string"},
            "default": []
          }
        },
        "required": ["company_name", "extraction_schema"]
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "research_queries": {
            "type": "array",
            "items": {"type": "string"}
          },
          "search_results": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "url": {"type": "string"},
                "title": {"type": "string"},
                "content": {"type": "string"}
              }
            }
          },
          "research_notes": {
            "type": "string",
            "description": "Structured research notes"
          },
          "metadata": {
            "type": "object",
            "properties": {
              "provider": {"type": "string"},
              "queries_executed": {"type": "integer"},
              "results_found": {"type": "integer"},
              "duration_seconds": {"type": "number"}
            }
          }
        }
      }
    }
  ],
  "resources": {
    "cpu": "8 cores",
    "memory": "16GB",
    "maxConcurrency": 5,
    "timeout": "120s"
  },
  "authentication": {
    "type": "bearer",
    "required": true
  }
}
```

**êµ¬í˜„ (Flask)**:
```python
# research_agent/app.py
from flask import Flask, request, jsonify
from src.agent.research import research_node
from src.agent.configuration import Configuration
import asyncio
import json

app = Flask(__name__)

# Agent Card
AGENT_CARD = {
    # ... (ìœ„ JSON)
}

# Concurrency limit
semaphore = asyncio.Semaphore(5)

@app.get("/.well-known/agent.json")
def get_agent_card():
    """Agent discovery endpoint"""
    return jsonify(AGENT_CARD)

@app.post("/tasks/send")
async def handle_research_task():
    """Handle synchronous research task"""
    task_request = request.get_json()
    task_id = task_request.get("id")

    # Extract input
    input_data = extract_input_from_task(task_request)

    # Validate input
    if not validate_input(input_data):
        return jsonify({
            "id": task_id,
            "status": {"state": "failed"},
            "error": "Invalid input schema"
        }), 400

    # Acquire semaphore (rate limiting)
    async with semaphore:
        try:
            # Execute research (reuse existing code!)
            config = Configuration(
                max_search_queries=input_data.get("max_queries", 3),
                search_provider=input_data.get("search_provider", "hybrid")
            )

            state = {
                "company_name": input_data["company_name"],
                "extraction_schema": input_data["extraction_schema"],
                "follow_up_queries": input_data.get("follow_up_queries", []),
                "research_queries": [],
                "search_results": [],
                "research_notes": "",
                "messages": []
            }

            result = await research_node(state, config)

            # Create A2A response
            response_task = {
                "id": task_id,
                "status": {"state": "completed"},
                "messages": [
                    task_request.get("message", {}),
                    {
                        "role": "agent",
                        "parts": [{
                            "text": json.dumps({
                                "research_queries": result["research_queries"],
                                "search_results": result["search_results"],
                                "research_notes": result["research_notes"],
                                "metadata": {
                                    "provider": config.search_provider,
                                    "queries_executed": len(result["research_queries"]),
                                    "results_found": len(result["search_results"])
                                }
                            })
                        }]
                    }
                ],
                "artifacts": []
            }

            return jsonify(response_task)

        except Exception as e:
            return jsonify({
                "id": task_id,
                "status": {"state": "failed"},
                "error": str(e)
            }), 500

@app.post("/tasks/submit")
async def handle_async_task():
    """Handle asynchronous research task"""
    # For long-running tasks
    # Store in Redis queue
    # Return task ID immediately
    pass

@app.get("/health")
def health_check():
    """Health check endpoint"""
    return jsonify({"status": "healthy"})

def extract_input_from_task(task):
    """Extract input data from A2A task"""
    try:
        message = task.get("message", {})
        parts = message.get("parts", [])
        if parts and "text" in parts[0]:
            return json.loads(parts[0]["text"])
    except:
        pass
    return {}

def validate_input(input_data):
    """Validate input schema"""
    required = ["company_name", "extraction_schema"]
    return all(k in input_data for k in required)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)
```

**Dockerfile**:
```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy agent code
COPY research_agent/ ./research_agent/
COPY src/ ./src/

# Expose port
EXPOSE 5001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:5001/health || exit 1

# Run agent
CMD ["python", "-m", "flask", "--app", "research_agent.app", "run", "--host=0.0.0.0", "--port=5001"]
```

---

### 2. Extraction Agent

**Agent Card**:
```json
{
  "name": "ExtractionAgent",
  "description": "Structured data extraction from research notes",
  "url": "http://extraction-{instance-id}:5002",
  "version": "3.0.0",
  "capabilities": {
    "streaming": false,
    "pushNotifications": false
  },
  "skills": [
    {
      "name": "extract_data",
      "description": "Extract structured JSON data from research notes",
      "input_schema": {
        "type": "object",
        "properties": {
          "research_notes": {"type": "string"},
          "extraction_schema": {"type": "object"},
          "company_name": {"type": "string"}
        },
        "required": ["research_notes", "extraction_schema"]
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "extracted_data": {"type": "object"},
          "confidence_score": {
            "type": "number",
            "minimum": 0,
            "maximum": 1
          }
        }
      }
    }
  ],
  "resources": {
    "cpu": "4 cores",
    "memory": "8GB",
    "maxConcurrency": 5,
    "timeout": "60s"
  }
}
```

**êµ¬í˜„ ì½”ë“œ**: (Research Agentì™€ ìœ ì‚¬í•œ íŒ¨í„´)

---

### 3. Reflection Agent

**Agent Card**:
```json
{
  "name": "ReflectionAgent",
  "description": "Quality evaluation and follow-up query generation",
  "url": "http://reflection-{instance-id}:5003",
  "version": "3.0.0",
  "skills": [
    {
      "name": "reflect_quality",
      "input_schema": {
        "type": "object",
        "properties": {
          "extracted_data": {"type": "object"},
          "extraction_schema": {"type": "object"},
          "company_name": {"type": "string"}
        },
        "required": ["extracted_data", "extraction_schema"]
      },
      "output_schema": {
        "type": "object",
        "properties": {
          "is_complete": {"type": "boolean"},
          "completeness_score": {"type": "number"},
          "missing_fields": {
            "type": "array",
            "items": {"type": "string"}
          },
          "follow_up_queries": {
            "type": "array",
            "items": {"type": "string"}
          },
          "quality_issues": {
            "type": "array",
            "items": {"type": "string"}
          }
        }
      }
    }
  ],
  "resources": {
    "cpu": "2 cores",
    "memory": "4GB",
    "maxConcurrency": 10,
    "timeout": "30s"
  }
}
```

---

### 4. Coordinator Agent

**ëª©ì **: ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

**êµ¬í˜„**:
```python
# coordinator/app.py
from fastapi import FastAPI, BackgroundTasks, HTTPException
from typing import List, Dict, Optional
import asyncio
import aiohttp
import uuid
from pydantic import BaseModel

app = FastAPI()

# Configuration
RESEARCH_AGENTS = [f"http://research-{i}:5001" for i in range(1, 11)]
EXTRACTION_AGENTS = [f"http://extraction-{i}:5002" for i in range(1, 6)]
REFLECTION_AGENTS = [f"http://reflection-{i}:5003" for i in range(1, 3)]

# Load balancers
research_pool = RoundRobinPool(RESEARCH_AGENTS)
extraction_pool = RoundRobinPool(EXTRACTION_AGENTS)
reflection_pool = RoundRobinPool(REFLECTION_AGENTS)

# Request/Response models
class CompanyResearchRequest(BaseModel):
    company_name: str
    extraction_schema: dict
    max_iterations: int = 2

class BatchResearchRequest(BaseModel):
    companies: List[str]
    extraction_schema: dict
    max_iterations: int = 2

class JobStatus(BaseModel):
    job_id: str
    status: str
    progress: Dict[str, int]
    results: Optional[List[Dict]] = None

# In-memory job store (use Redis in production)
jobs: Dict[str, JobStatus] = {}

@app.post("/research/single")
async def research_single_company(request: CompanyResearchRequest):
    """Synchronous single company research"""

    result = await process_single_company(
        request.company_name,
        request.extraction_schema,
        request.max_iterations
    )

    return result

@app.post("/research/batch")
async def research_batch(
    request: BatchResearchRequest,
    background_tasks: BackgroundTasks
):
    """Asynchronous batch research"""

    job_id = str(uuid.uuid4())

    # Initialize job
    jobs[job_id] = JobStatus(
        job_id=job_id,
        status="submitted",
        progress={
            "total": len(request.companies),
            "completed": 0,
            "failed": 0
        }
    )

    # Run in background
    background_tasks.add_task(
        run_batch_job,
        job_id,
        request.companies,
        request.extraction_schema,
        request.max_iterations
    )

    return {
        "job_id": job_id,
        "status": "submitted",
        "total_companies": len(request.companies)
    }

@app.get("/jobs/{job_id}")
async def get_job_status(job_id: str):
    """Get job status"""

    if job_id not in jobs:
        raise HTTPException(status_code=404, detail="Job not found")

    return jobs[job_id]

async def run_batch_job(
    job_id: str,
    companies: List[str],
    schema: dict,
    max_iterations: int
):
    """Background batch processing"""

    jobs[job_id].status = "running"

    # Progress tracker
    progress = ProgressTracker(len(companies))

    # Process all companies in parallel
    tasks = [
        process_single_company_with_tracking(
            company,
            schema,
            max_iterations,
            progress
        )
        for company in companies
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # Separate success/failure
    success = [r for r in results if not isinstance(r, Exception)]
    failed = [r for r in results if isinstance(r, Exception)]

    # Update job status
    jobs[job_id].status = "completed"
    jobs[job_id].progress["completed"] = len(success)
    jobs[job_id].progress["failed"] = len(failed)
    jobs[job_id].results = success

async def process_single_company(
    company_name: str,
    schema: dict,
    max_iterations: int
) -> Dict:
    """Process single company through R-E-R loop"""

    follow_up_queries = []
    iteration = 0

    while iteration < max_iterations:
        # Phase 1: Research
        research_result = await send_a2a_task(
            research_pool.get_next(),
            "research_company",
            {
                "company_name": company_name,
                "extraction_schema": schema,
                "follow_up_queries": follow_up_queries
            }
        )

        # Phase 2: Extraction
        extraction_result = await send_a2a_task(
            extraction_pool.get_next(),
            "extract_data",
            {
                "research_notes": research_result["research_notes"],
                "extraction_schema": schema,
                "company_name": company_name
            }
        )

        # Phase 3: Reflection
        reflection_result = await send_a2a_task(
            reflection_pool.get_next(),
            "reflect_quality",
            {
                "extracted_data": extraction_result["extracted_data"],
                "extraction_schema": schema,
                "company_name": company_name
            }
        )

        # Check completion
        if reflection_result["is_complete"]:
            return {
                "company_name": company_name,
                "data": extraction_result["extracted_data"],
                "iterations": iteration + 1,
                "complete": True,
                "completeness_score": reflection_result["completeness_score"]
            }

        # Continue with follow-up
        follow_up_queries = reflection_result["follow_up_queries"]
        iteration += 1

    # Max iterations reached
    return {
        "company_name": company_name,
        "data": extraction_result["extracted_data"],
        "iterations": iteration,
        "complete": False,
        "completeness_score": reflection_result["completeness_score"]
    }

async def send_a2a_task(
    agent_url: str,
    skill_name: str,
    input_data: dict,
    max_retries: int = 3
) -> dict:
    """Send A2A task with retry logic"""

    for attempt in range(max_retries):
        try:
            task = {
                "id": str(uuid.uuid4()),
                "message": {
                    "role": "user",
                    "parts": [{"text": json.dumps(input_data)}]
                }
            }

            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{agent_url}/tasks/send",
                    json=task,
                    timeout=aiohttp.ClientTimeout(total=120)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return extract_result_from_task(result)
                    elif response.status == 429:
                        # Rate limit - try different agent
                        if attempt < max_retries - 1:
                            await asyncio.sleep(2 ** attempt)
                            continue
                    else:
                        raise Exception(f"HTTP {response.status}")

        except Exception as e:
            if attempt < max_retries - 1:
                await asyncio.sleep(2 ** attempt)
                continue
            raise

def extract_result_from_task(task_result: dict) -> dict:
    """Extract data from A2A task response"""
    messages = task_result.get("messages", [])
    if len(messages) > 1:
        agent_message = messages[-1]
        for part in agent_message.get("parts", []):
            if "text" in part:
                return json.loads(part["text"])
    return {}

class RoundRobinPool:
    """Simple round-robin load balancer"""
    def __init__(self, agents: List[str]):
        self.agents = agents
        self.index = 0
        self.lock = asyncio.Lock()

    async def get_next(self) -> str:
        async with self.lock:
            agent = self.agents[self.index]
            self.index = (self.index + 1) % len(self.agents)
            return agent

class ProgressTracker:
    """Thread-safe progress tracker"""
    def __init__(self, total: int):
        self.total = total
        self.completed = 0
        self.failed = 0
        self.lock = asyncio.Lock()

    async def increment(self, failed: bool = False):
        async with self.lock:
            self.completed += 1
            if failed:
                self.failed += 1

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000)
```

---

## í†µì‹  í”„ë¡œí† ì½œ

### A2A Task Lifecycle

```
1. Discovery
   Client â†’ GET http://agent:5001/.well-known/agent.json
   Agent â†’ Agent Card (JSON)

2. Task Submission
   Client â†’ POST http://agent:5001/tasks/send
   {
     "id": "task-123",
     "message": {
       "role": "user",
       "parts": [{"text": "{...input...}"}]
     }
   }

3. Processing
   Agent â†’ state: "working"

4. Completion
   Agent â†’ Response
   {
     "id": "task-123",
     "status": {"state": "completed"},
     "messages": [
       {...user message...},
       {
         "role": "agent",
         "parts": [{"text": "{...output...}"}]
       }
     ]
   }
```

### Error Handling

```python
# Retry with exponential backoff
async def send_with_retry(agent_url, task, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = await send_task(agent_url, task)
            return response
        except aiohttp.ClientError as e:
            if attempt < max_retries - 1:
                await asyncio.sleep(2 ** attempt)
                continue
            raise

# Fallback to different provider
try:
    result = await send_task(tavily_agent, task)
except RateLimitError:
    result = await send_task(google_agent, task)
```

---

## í™•ì¥ì„± ì „ëµ

### ìˆ˜í‰ í™•ì¥ (Horizontal Scaling)

```yaml
# docker-compose.scale.yml
version: '3.8'

services:
  research:
    image: company-research:research-agent
    deploy:
      replicas: 10  # Scale to 10 instances
      resources:
        limits:
          cpus: '8'
          memory: 16G
    environment:
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}

  extraction:
    image: company-research:extraction-agent
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: '4'
          memory: 8G

  reflection:
    image: company-research:reflection-agent
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 4G
```

### Kubernetes Auto-scaling

```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: research-agent-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: research-agent
  minReplicas: 5
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

---

## ì„±ëŠ¥ ë° ë¹„ìš©

### ì²˜ë¦¬ ì„±ëŠ¥

| ë©”íŠ¸ë¦­ | ëª¨ë†€ë¦¬ì‹ (v2.0) | A2A ë¶„ì‚° (v3.0) | ê°œì„  |
|--------|----------------|----------------|------|
| **1,000 companies** | 12-25ì‹œê°„ | 90ì´ˆ | **480-1000x** |
| **ì²˜ë¦¬ëŸ‰/ì‹œê°„** | 40-80 | 400-800 | **10x** |
| **ë™ì‹œ ì²˜ë¦¬** | 1 | 100+ | **100x** |
| **í‰ê·  ë ˆì´í„´ì‹œ** | N/A (ë°°ì¹˜ only) | 0.8ì´ˆ/íšŒì‚¬ | **ì‹¤ì‹œê°„** |

### ë¹„ìš© ë¶„ì„

#### ì¸í”„ë¼ ë¹„ìš© (ì›”ê°„, AWS ê¸°ì¤€)

| êµ¬ì„± ìš”ì†Œ | ì‚¬ì–‘ | ìˆ˜ëŸ‰ | ë‹¨ê°€ | ì›” ë¹„ìš© |
|----------|------|------|------|--------|
| **Research Agent** | c5.2xlarge (8 CPU, 16GB) | 10 | $0.34/h | $2,448 |
| **Extraction Agent** | c5.xlarge (4 CPU, 8GB) | 5 | $0.17/h | $612 |
| **Reflection Agent** | t3.medium (2 CPU, 4GB) | 2 | $0.042/h | $60 |
| **Coordinator** | t3.large (2 CPU, 8GB) | 1 | $0.083/h | $60 |
| **RDS PostgreSQL** | db.t3.large | 1 | $0.145/h | $104 |
| **ElastiCache Redis** | cache.t3.medium | 1 | $0.068/h | $49 |
| **S3** | Standard | - | - | $50 |
| **ALB** | - | 1 | - | $22 |
| **Data Transfer** | - | - | - | $100 |
| **ì´ê³„** | | | | **$3,505** |

#### API ë¹„ìš© (ì›”ê°„, 10,000 companies ê¸°ì¤€)

| API | ë‹¨ê°€ | ì‚¬ìš©ëŸ‰ | ë¹„ìš© |
|-----|------|--------|------|
| **Claude Sonnet 4.5** | $3/$15 per 1M | ~100M tokens | $300-1,500 |
| **Tavily** (50% queries) | $0.005/ì¿¼ë¦¬ | 15,000 | $75 |
| **Google ADK** (50% queries) | ë¬´ë£Œ | 15,000 | $0 |
| **ì´ê³„** | | | **$375-1,575** |

#### ì´ ë¹„ìš©

```
ì›”ê°„ ì´ ë¹„ìš©: $3,505 (ì¸í”„ë¼) + $375-1,575 (API) = $3,880-5,080

ì›”ê°„ ì²˜ë¦¬ëŸ‰: 400 companies/hour Ã— 720 hours = 288,000 companies

íšŒì‚¬ë‹¹ ë¹„ìš©: $3,880 / 288,000 = $0.0135
          ë˜ëŠ” $5,080 / 288,000 = $0.0176

vs ëª¨ë†€ë¦¬ì‹: $0.007 (í•˜ì§€ë§Œ ì²˜ë¦¬ëŸ‰ 1/10)

ì‹¤ì œ ë¹„ìš© íš¨ìœ¨: 10ë°° ë¹ ë¥¸ ì²˜ë¦¬ë¡œ ì¸í•œ ê¸°íšŒë¹„ìš© ì ˆê°
```

---

## ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

### Phase 1: Hybrid ì‹œì‘ (2ì£¼)

**ëª©í‘œ**: ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš© + A2A ë˜í¼

```
í˜„ì¬ LangGraph ì‹œìŠ¤í…œ
    â†“
A2A ë˜í¼ ì¶”ê°€ (Flask/FastAPI)
    â†“
3ê°œ ì—ì´ì „íŠ¸ ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥
```

**ì‘ì—…**:
1. Research Agent ë˜í¼ êµ¬í˜„
2. Extraction Agent ë˜í¼ êµ¬í˜„
3. Reflection Agent ë˜í¼ êµ¬í˜„
4. Docker Compose ì„¤ì •
5. ë¡œì»¬ í…ŒìŠ¤íŠ¸ (10ê°œ íšŒì‚¬)

### Phase 2: Coordinator êµ¬í˜„ (2ì£¼)

**ëª©í‘œ**: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë ˆì´ì–´

```
Coordinator Agent êµ¬í˜„
    â†“
ë¡œë“œ ë°¸ëŸ°ì‹± + ì¬ì‹œë„ ë¡œì§
    â†“
100ê°œ íšŒì‚¬ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
```

**ì‘ì—…**:
1. Coordinator FastAPI ì„œë²„
2. Round-robin ë¡œë“œ ë°¸ëŸ°ì„œ
3. A2A í†µì‹  í´ë¼ì´ì–¸íŠ¸
4. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„
5. ì§„í–‰ ìƒí™© ì¶”ì 

### Phase 3: ì¸í”„ë¼ êµ¬ì¶• (2ì£¼)

**ëª©í‘œ**: í”„ë¡œë•ì…˜ ì¸í”„ë¼

```
Docker â†’ Docker Compose â†’ Kubernetes
```

**ì‘ì—…**:
1. PostgreSQL + Redis ì„¤ì •
2. S3 ë²„í‚· ìƒì„±
3. Kubernetes manifest ì‘ì„±
4. Helm chart ì‘ì„±
5. CI/CD íŒŒì´í”„ë¼ì¸ (GitHub Actions)

### Phase 4: ì„±ëŠ¥ ìµœì í™” (2ì£¼)

**ëª©í‘œ**: 1,000ê°œ íšŒì‚¬ ì²˜ë¦¬ ê²€ì¦

```
ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ â†’ ë³‘ëª© ë¶„ì„ â†’ ìµœì í™”
```

**ì‘ì—…**:
1. ë¶€í•˜ í…ŒìŠ¤íŠ¸ (Locust)
2. ë³‘ëª© ë¶„ì„ (Prometheus)
3. ìºì‹± ìµœì í™”
4. Connection pooling
5. Auto-scaling íŠœë‹

### Phase 5: í”„ë¡œë•ì…˜ ë°°í¬ (1ì£¼)

**ëª©í‘œ**: ì‹¤ì œ ìš´ì˜ ì „í™˜

```
Staging ê²€ì¦ â†’ Production ë°°í¬ â†’ ëª¨ë‹ˆí„°ë§
```

**ì‘ì—…**:
1. Staging í™˜ê²½ ë°°í¬
2. ì‹¤ì œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
3. Production ë°°í¬ (Blue-Green)
4. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì„¤ì •
5. ìš´ì˜ ë¬¸ì„œ ì‘ì„±

**ì´ ê¸°ê°„**: 9ì£¼

---

## ë‹¤ìŒ ë‹¨ê³„

1. **ì¸í”„ë¼ ì„¤ê³„ ë¬¸ì„œ** ì‘ì„± (INFRASTRUCTURE_DESIGN.md)
2. **ë°ì´í„° í”Œë¡œìš° ì„¤ê³„** ì‘ì„± (DATA_FLOW_DESIGN.md)
3. **API ëª…ì„¸** ì‘ì„± (API_SPECIFICATION.md)
4. **ë°°í¬ ì „ëµ** ìƒì„¸í™” (DEPLOYMENT_STRATEGY.md)
5. **Phase 1 êµ¬í˜„** ì‹œì‘

---

**ì‘ì„±**: 2025-10-22
**ë²„ì „**: 3.0.0-design
**ìƒíƒœ**: Architecture approved, ready for implementation
